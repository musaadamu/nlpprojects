{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision transformers pandas gradio\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gradio as gr\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/nlp_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def load_image(image_id, image_folder='images'):\n",
    "    image_path = os.path.join(image_folder, f\"{image_id}.png\")  # Adjust extension if needed\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"FileNotFoundError: Image {image_path} not found.\")\n",
    "        raise FileNotFoundError(f\"Image {image_path} not found.\")\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image)\n",
    "\n",
    "# Create label mapping\n",
    "unique_labels = data['answer'].unique()\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(\"Label mapping:\", label_map)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"Validation data size:\", len(val_data))\n",
    "\n",
    "# Function to prepare dataset\n",
    "def prepare_dataset(data, label_map, tokenizer, image_folder):\n",
    "    images = []\n",
    "    questions = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        try:\n",
    "            # Load and transform the image\n",
    "            image_tensor = load_image(row['image_id'], image_folder)\n",
    "            images.append(image_tensor)\n",
    "            questions.append(row['englishquestion'])\n",
    "            labels.append(label_map[row['answer']])\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    # Tokenize questions\n",
    "    question_tokens = tokenizer(questions, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    print(f\"Questions tokenized shape: {question_tokens['input_ids'].shape}\")\n",
    "\n",
    "    # Convert labels to a tensor\n",
    "    label_tensor = torch.tensor(labels)\n",
    "    print(f\"Labels tensor shape: {label_tensor.shape}\")\n",
    "\n",
    "    # Stack images into a single tensor\n",
    "    image_stack = torch.stack(images)\n",
    "    print(f\"Images stacked shape: {image_stack.shape}\")\n",
    "\n",
    "    dataset = TensorDataset(question_tokens['input_ids'], question_tokens['attention_mask'], image_stack, label_tensor)\n",
    "    return dataset\n",
    "\n",
    "# Prepare training and validation datasets\n",
    "train_dataset = prepare_dataset(train_data, label_map, tokenizer, image_folder='images')\n",
    "val_dataset = prepare_dataset(val_data, label_map, tokenizer, image_folder='images')\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"Data preparation successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertCNNModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(768 + 128, len(label_map))  # Adjust the output size to match number of labels\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, images):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        cnn_output = self.cnn(images).view(images.size(0), -1)\n",
    "        combined_output = torch.cat((bert_output, cnn_output), dim=1)\n",
    "        output = self.fc(combined_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = BertCNNModel().to(device)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    _, preds = torch.max(predictions, dim=1)\n",
    "    return torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, images, labels = [x.to(device) for x in batch]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(labels)\n",
    "        total_correct += calculate_accuracy(outputs, labels) * len(labels)\n",
    "        total_samples += len(labels)\n",
    "        \n",
    "    train_loss = total_loss / total_samples\n",
    "    train_accuracy = total_correct / total_samples\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "    \n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, images, labels = [x.to(device) for x in batch]\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item() * len(labels)\n",
    "            val_correct += calculate_accuracy(outputs, labels) * len(labels)\n",
    "            val_samples += len(labels)\n",
    "            \n",
    "    val_loss = val_loss / val_samples\n",
    "    val_accuracy = val_correct / val_samples\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(question, image):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Preprocess input\n",
    "        question_tokens = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        outputs = model(question_tokens['input_ids'], question_tokens['attention_mask'], image_tensor)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        prediction = list(label_map.keys())[preds.item()]\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "# Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter the question here...\"),\n",
    "        gr.Image(type=\"pil\")\n",
    "    ],\n",
    "    outputs=\"text\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
